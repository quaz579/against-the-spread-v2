# Contributing to Against The Spread

Thank you for your interest in contributing! This project uses AI-assisted development with human code review.

## ğŸ¤– AI-Assisted Development

This project is designed to be implemented primarily by AI agents with human oversight. Before contributing, please:

1. **Read [`.agents.md`](.agents.md)** - Complete guide for AI agents
2. **Review [`implementation-plan.md`](implementation-plan.md)** - Detailed implementation steps
3. **Follow the testing strategy** - Tests must be written first (TDD)
4. **Check frequently** - Compile and test after each change

## ğŸ“‹ Development Workflow

### For AI Agents

1. **Review Context**
   - Read `.agents.md` for project structure and guidelines
   - Review relevant sections of `implementation-plan.md`
   - Understand the current phase of development

2. **Implement Feature**
   - Write failing tests first (TDD)
   - Implement minimum code to pass tests
   - Refactor and optimize
   - Update documentation

3. **Validate Changes**
   - Run `dotnet build` - ensure compilation succeeds
   - Run `dotnet test` - ensure all unit tests pass (156+ tests)
   - Run E2E tests - `./start-e2e.sh && cd tests && npm test` (2+ tests)
   - Test locally with Azurite and browsers
   - Verify changes against acceptance criteria
   - **A task is NOT complete until ALL tests pass**

4. **Commit Changes**
   - Use clear, descriptive commit messages
   - Follow conventional commits format
   - Reference issue numbers where applicable

### For Human Reviewers

1. **Review Phase**
   - Check that tests were written first
   - Verify all tests pass
   - Review code quality and adherence to patterns
   - Test locally if needed
   - Provide feedback or approve

2. **Approval Criteria**
   - All tests passing
   - Code follows established patterns
   - Documentation updated
   - No security issues
   - Performance acceptable

## ğŸ§ª Testing Requirements

All contributions MUST include tests:

**CRITICAL: All tests must pass before any PR is merged:**
- Unit tests: `dotnet test` (156+ tests)
- E2E tests: `cd tests && npm test` (2+ tests, requires `./start-e2e.sh`)

### Unit Tests
- Test all business logic
- Mock external dependencies
- Use AAA pattern (Arrange, Act, Assert)
- Clear test names describing scenario

Example:
```csharp
[Fact]
public void ParseLinesFromExcel_WithValidFile_ReturnsWeeklyLines()
{
    // Arrange
    var service = new ExcelService();
    var stream = GetTestFileStream();
    
    // Act
    var result = service.ParseLinesFromExcel(stream);
    
    // Assert
    result.Should().NotBeNull();
    result.Week.Should().Be(1);
}
```

### Integration Tests
- Test with Azurite (local Azure Storage)
- Test API endpoints end-to-end
- Validate file operations

### Component Tests (Blazor)
- Use bUnit for component testing
- Test user interactions
- Verify rendered output

### End-to-End Tests (Playwright)
- Validate complete user flows
- Test admin authentication and uploads
- Verify Excel download format
- See `tests/README.md` for complete guide
- Add new tests for significant UI/API changes

## ğŸ—ï¸ Code Structure

### Project Organization
```
AgainstTheSpread.Core/
â”œâ”€â”€ Models/              # Domain models
â”œâ”€â”€ Interfaces/          # Service contracts
â””â”€â”€ Services/            # Business logic

AgainstTheSpread.Functions/
â”œâ”€â”€ Functions/           # HTTP triggers
â””â”€â”€ Program.cs          # DI configuration

AgainstTheSpread.Web/
â”œâ”€â”€ Pages/              # Razor pages
â”œâ”€â”€ Components/         # Reusable components
â””â”€â”€ Services/           # API client

AgainstTheSpread.Tests/
â”œâ”€â”€ Models/             # Model tests
â”œâ”€â”€ Services/           # Service tests
â”œâ”€â”€ Functions/          # API tests
â”œâ”€â”€ Web/                # Component tests
â””â”€â”€ Integration/        # E2E tests
```

### Naming Conventions

**Tests:**
- `MethodName_Scenario_ExpectedBehavior`
- Example: `GetLinesAsync_WithValidWeek_ReturnsWeeklyLines`

**Classes:**
- PascalCase for public members
- Descriptive names
- Interface prefix: `IServiceName`

**Files:**
- Match class name
- One class per file

## ğŸ“ Commit Message Format

Follow Conventional Commits:

```
<type>(<scope>): <subject>

<body>

<footer>
```

**Types:**
- `feat`: New feature
- `fix`: Bug fix
- `test`: Adding tests
- `refactor`: Code refactoring
- `docs`: Documentation
- `chore`: Maintenance tasks
- `ci`: CI/CD changes

**Examples:**
```
feat(core): add Excel parsing service

Implements ExcelService with EPPlus to parse weekly lines
from uploaded Excel files. Includes comprehensive tests.

Closes #12

---

test(functions): add unit tests for admin endpoints

Adds tests for upload lines functionality with mocked
storage and Excel services.

---

fix(web): correct game selection validation

Fixes issue where users could select more than 6 games.
Adds validation and disables further selection.

Fixes #45
```

## ğŸ” Code Review Checklist

Reviewers should verify:

- [ ] Tests written before implementation (TDD)
- [ ] All unit tests pass (`dotnet test` - 156+ tests)
- [ ] All E2E tests pass (`cd tests && npm test` - 2+ tests)
- [ ] Code compiles without warnings
- [ ] Documentation updated
- [ ] Follows established patterns
- [ ] No hardcoded values
- [ ] Error handling implemented
- [ ] Security considerations addressed
- [ ] Performance acceptable
- [ ] Mobile-friendly (for UI changes)
- [ ] New E2E tests added for significant UI changes

## ğŸš« What NOT to Do

- âŒ Don't skip tests
- âŒ Don't commit code that doesn't compile
- âŒ Don't commit failing tests
- âŒ Don't hardcode credentials or secrets
- âŒ Don't make breaking changes without discussion
- âŒ Don't submit large PRs (break into smaller pieces)
- âŒ Don't ignore code review feedback

## âœ… What TO Do

- âœ… Write tests first
- âœ… Compile and test frequently
- âœ… Keep commits small and focused
- âœ… Update documentation
- âœ… Follow the implementation plan
- âœ… Ask questions when unclear
- âœ… Reference issues in commits
- âœ… Be responsive to code review

## ğŸ¯ Current Development Phase

Check [`implementation-plan.md`](implementation-plan.md) to see:
- Current phase of development
- What's been completed
- What's next to implement
- Success criteria for each phase

## ğŸ“š Required Reading

Before contributing:
1. [`.agents.md`](.agents.md) - Agent development guide
2. [`implementation-plan.md`](implementation-plan.md) - Implementation roadmap
3. [`README.md`](README.md) - Project overview
4. [`TESTING.md`](TESTING.md) - Unit testing guide
5. [`tests/README.md`](tests/README.md) - **E2E testing guide (Playwright)**
6. Game rules in [`reference-docs/rules.md`](reference-docs/rules.md)

## ğŸ› Reporting Issues

When reporting issues:
1. Use the issue template
2. Provide clear reproduction steps
3. Include error messages/stack traces
4. Specify environment (OS, .NET version, etc.)
5. Include relevant logs

## ğŸ’¡ Suggesting Features

Feature requests should:
1. Describe the problem being solved
2. Propose a solution
3. Consider impact on existing features
4. Be aligned with project goals
5. Include acceptance criteria

## ğŸ” Security

If you discover a security vulnerability:
1. **DO NOT** open a public issue
2. Email the maintainer directly
3. Provide detailed information
4. Wait for response before disclosure

## ğŸ“ Getting Help

- Create an issue for bugs or questions
- Tag issues appropriately
- Be patient and respectful
- Provide context and examples

## ğŸ™ Thank You

Your contributions make this project better! We appreciate your time and effort in following these guidelines.

---

**Remember**: This is an AI-assisted project. The goal is for agents to implement features while humans review for quality and correctness.
